# ========== ğŸ”§ å¯¼å…¥å¿…è¦çš„åº“ ==========
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ========== ğŸ“‚ ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ•°æ® ==========
# ä»æœ¬åœ°è¯»å–CSVæ–‡ä»¶
df = pd.read_csv('malicious_phish.csv')

# æ‰“å°å‰å‡ è¡Œï¼Œç¡®è®¤æ•°æ®ç»“æ„ï¼ˆå¯é€‰ï¼‰
# print("ã€åŸå§‹æ•°æ®é¢„è§ˆã€‘")
# print(df.head())

# ========== ğŸ§¹ ç¬¬äºŒæ­¥ï¼šæ•°æ®é¢„å¤„ç† ==========

# å°†å¤šç±»åˆ«çš„"type"æ ‡ç­¾ï¼ˆbenign, phishingç­‰ï¼‰è½¬æ¢ä¸ºäºŒåˆ†ç±»æ ‡ç­¾
# benign â†’ 0ï¼ˆæ­£å¸¸ç½‘å€ï¼‰ï¼Œå…¶ä½™å¦‚ phishing/malware/defacement â†’ 1ï¼ˆæ¶æ„ç½‘å€ï¼‰
df['label'] = df['type'].apply(lambda x: 0 if x == 'benign' else 1)

# è¾“å‡ºå¤„ç†åçš„æ ‡ç­¾åˆ†å¸ƒ
print("\nã€äºŒåˆ†ç±»æ ‡ç­¾åˆ†å¸ƒã€‘")
print(df['label'].value_counts())

# ========== ğŸ”¡ ç¬¬ä¸‰æ­¥ï¼šç‰¹å¾æå–ï¼ˆæ–‡æœ¬å‘é‡åŒ–ï¼‰ ==========
# ä½¿ç”¨ TF-IDF ç®—æ³•å°†ç½‘å€å­—ç¬¦ä¸²è½¬æ¢ä¸ºç¨€ç–çŸ©é˜µç‰¹å¾ï¼ˆå‘é‡å½¢å¼ï¼‰
vectorizer = TfidfVectorizer()
# X = vectorizer.fit_transform(df['url'])  # ç‰¹å¾çŸ©é˜µ
# y = df['label']                          # æ ‡ç­¾åˆ—

# ========== ğŸ“¦ ç¬¬å››æ­¥ï¼šåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›† ==========
# å°†æ•°æ®æŒ‰ 8:2 åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
# X_train, X_test, y_train, y_test = train_test_split(
#     X, y, test_size=0.2, random_state=42
# )

# ========== ğŸ§  ç¬¬äº”æ­¥ï¼šæ¨¡å‹è®­ç»ƒ ==========
# ä½¿ç”¨æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨è¿›è¡Œè®­ç»ƒï¼ˆé€‚åˆæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼‰
# model = MultinomialNB()
# model.fit(X_train, y_train)

# ========== ğŸ” ç¬¬å…­æ­¥ï¼šæ¨¡å‹é¢„æµ‹ä¸è¯„ä¼° ==========
# ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹
# y_pred = model.predict(X_test)

# è®¡ç®—æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„å‡†ç¡®ç‡
# acc = accuracy_score(y_test, y_pred)
# print(f"\nâœ… æ¨¡å‹å‡†ç¡®ç‡ï¼š{acc:.4f}")

# æ‰“å°æ›´è¯¦ç»†çš„åˆ†ç±»æŠ¥å‘Šï¼ˆåŒ…å«ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ï¼‰
# print("\nğŸ“‹ åˆ†ç±»æŠ¥å‘Šï¼ˆClassification Reportï¼‰:")
# print(classification_report(y_test, y_pred))

# æ‰“å°æ··æ·†çŸ©é˜µï¼ˆä¾¿äºäº†è§£åˆ†ç±»é”™è¯¯æƒ…å†µï¼‰
# print("\nğŸ“Š æ··æ·†çŸ©é˜µï¼ˆConfusion Matrixï¼‰:")
# print(confusion_matrix(y_test, y_pred))


from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression

# æŠ½æ ·
df_sampled = df.sample(n=80000, random_state=42)

# ç‰¹å¾å¤„ç†
X = vectorizer.fit_transform(df_sampled['url'])
y = df_sampled['label']

# åˆ’åˆ†æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

# æ¨¡å‹åˆ—è¡¨ï¼ˆå‡å°éšæœºæ£®æ—æ ‘æ•°ï¼‰
models = {
    "Naive Bayes": MultinomialNB(),
    "Random Forest": RandomForestClassifier(n_estimators=20, random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=1000, solver='liblinear')
}

for name, model in models.items():
    print(f"\nğŸš€ æ­£åœ¨è®­ç»ƒæ¨¡å‹ï¼š{name}")
    model.fit(X_train, y_train)  # è®­ç»ƒæ¨¡å‹
    y_pred = model.predict(X_test)  # é¢„æµ‹ç»“æœ

    acc = accuracy_score(y_test, y_pred)
    print(f"âœ… æ¨¡å‹å‡†ç¡®ç‡ï¼š{acc:.4f}")
    print("ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, y_pred, zero_division=0))
    print("ğŸ“Š æ··æ·†çŸ©é˜µ:")
    print(confusion_matrix(y_test, y_pred))


import joblib

# å‡è®¾éšæœºæ£®æ—è¡¨ç°æœ€å¥½ï¼Œä¿å­˜å®ƒ
joblib.dump(models["Random Forest"], "rf_model.pkl")
joblib.dump(vectorizer, "tfidf_vectorizer.pkl")
